{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aade6907-4f0b-446c-bd1f-fc61a4479ae1",
   "metadata": {},
   "source": [
    "### **Homework #4 — Exploratory Data Analysis (EDA)**\n",
    "\n",
    "**Project:** Analysis of trends in conspiracy theories during 2020 and the influence of the COVID-19 pandemiс\n",
    "\n",
    "**Authors:** Hovoryshcheva Veronika, Morozova Polina\n",
    "\n",
    "**Team ID:** 15\n",
    "\n",
    "**Dataset:** normalized_data.csv\n",
    "\n",
    "**Time spent:** blabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59afea86-ee29-43b3-9d6e-64a6e99a3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = \"13:53, 31.10.2025\"\n",
    "\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67532a1d-5f67-42e4-a704-16ff66d6be72",
   "metadata": {},
   "source": [
    "### **Goal**\n",
    "\n",
    "The goal of this exploratory data analysis is to understand Reddit discussions about conspiracy theories in 2020, focusing on dataset structure, user activity, and subreddit interactions. It also aims to examine sentiment and emotional tone, identify recurring narratives and key phrases, and explore topic-specific patterns, such as COVID-related discussions and skepticism toward mainstream information. The analysis seeks to reveal dominant narratives, engagement patterns, and language trends across communities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affb4ed5-2ef2-4945-be9d-a7162e71e962",
   "metadata": {},
   "source": [
    "### **List of the Research Questions**\n",
    "#### Overview\n",
    "\n",
    "1. How many total records does the dataset contain, and how are they divided between submissions and comments?\n",
    "2. What is the timeframe covered by the dataset?\n",
    "3. What basic information can be summarized about the dataset (columns, data types, missing values)?\n",
    "4. Which specific conspiracy theories were most frequently discussed in 2020?\n",
    "\n",
    "#### Activity and Distribution\n",
    "\n",
    "5. Which are the top 10 most active subreddits by number of posts/comments?\n",
    "6. Are there significant peaks of activity around major real-world events?\n",
    "7. How many unique authors are there, and how many contributions did each make?\n",
    "8. Which subreddits have the highest average score versus the highest post volume?\n",
    "9. Do different subreddits experience synchronized activity peaks?\n",
    "10. Do the most active authors post in many subreddits or focus on one community?\n",
    "11. How does the average score (karma/upvotes) change over time?\n",
    "\n",
    "#### Sentiment Analysis\n",
    "\n",
    "12. What is the overall sentiment distribution of all comments and submissions?\n",
    "13. What are the most positive and most negative subreddits overall?\n",
    "14. Are longer comments more emotionally expressive (stronger positive/negative values)?\n",
    "15. How does sentiment vary between submissions and comments?\n",
    "16. Do posts with more positive sentiment tend to get higher scores?\n",
    "\n",
    "#### Interesring Findings\n",
    "\n",
    "17. Can recurring narratives or metaphors be identified?\n",
    "18. Which grammatical constructions are most common (imperative, interrogative, emotional)?\n",
    "19. Has skepticism toward official statistics and mainstream media increased during the pandemic?\n",
    "20. Does the language of users who discuss COVID differ from that of those discussing other conspiracy topics?\n",
    "21. Do topics with religious undertones have longer discussion threads?\n",
    "22. Which keywords most strongly co-occur with “COVID” or “virus”?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68423c1-e8e0-4994-868b-57d80c5edb2a",
   "metadata": {},
   "source": [
    "### **Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e97ca-aa88-48bc-9634-e6d49a2b5caa",
   "metadata": {},
   "source": [
    "#### **Q1** How many total records does the dataset contain, and how are they divided between submissions and comments?\n",
    "Understanding the overall size and internal balance of the dataset helps evaluate the representativeness of the material and determine whether conspiracy theories spread mainly through original posts or through ongoing discussions in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e900069-0176-4c35-82cb-f2ba306c10ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Desktop\\uni\\CSS\\project\\dataset.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf2ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Record Type\"] = df[\"is_submission\"].map({True: \"Submission\", False: \"Comment\"})\n",
    "\n",
    "counts = df[\"Record Type\"].value_counts().reset_index()\n",
    "counts.columns = [\"Record Type\", \"Count\"]\n",
    "counts[\"Percentage\"] = (counts[\"Count\"] / counts[\"Count\"].sum() * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e571098",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    counts,\n",
    "    x=\"Count\",\n",
    "    y=\"Record Type\",\n",
    "    orientation=\"h\",\n",
    "    color=\"Record Type\",\n",
    "    color_discrete_map={\"Submission\": \"#0c2688\", \"Comment\": \"#26A57F\"},\n",
    "    title=\"Distribution of Submissions vs Comments\",\n",
    "    text=counts.apply(lambda r: f\"{r['Count']:,} ({r['Percentage']}%)\", axis=1)\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Number of Records\",\n",
    "    yaxis_title=\"Record Type\",\n",
    "    title_font_size=18,\n",
    "    plot_bgcolor=\"white\"\n",
    ")\n",
    "fig.update_traces(textposition=\"outside\")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd7d90-eb67-483d-b973-cdf02a583e7e",
   "metadata": {},
   "source": [
    "#### **Q2** What is the timeframe covered by the dataset?\n",
    "Clarifying the temporal boundaries allows the analysis to be contextualized within specific stages of the COVID-19 pandemic and to trace how discussions evolved alongside major social or political events in 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f7e04-b960-434b-84df-aed831cd902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"created\"] = pd.to_datetime(df[\"created\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"created\"])\n",
    "\n",
    "\n",
    "df[\"month\"] = df[\"created\"].dt.month_name().str[:3]\n",
    "df[\"year\"] = df[\"created\"].dt.year\n",
    "month_counts = (\n",
    "    df.groupby([\"year\", \"month\"]).size().reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "month_order = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n",
    "               \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "month_counts[\"month\"] = pd.Categorical(month_counts[\"month\"], categories=month_order, ordered=True)\n",
    "month_counts = month_counts.sort_values([\"year\", \"month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb98621",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_counts[\"label\"] = month_counts[\"month\"].astype(str)\n",
    "\n",
    "fig = px.bar(\n",
    "    month_counts,\n",
    "    x=\"label\",\n",
    "    y=\"Count\",\n",
    "    text=\"Count\",\n",
    "    color_discrete_sequence=[\"#0c2688\"]\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition=\"outside\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Dataset Timeframe — Monthly Distribution of Records\",\n",
    "    xaxis_title=\"Month\",\n",
    "    yaxis_title=\"Number of Posts + Comments\",\n",
    "    showlegend=False,\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    xaxis=dict(\n",
    "        type=\"category\",\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        gridwidth=1,\n",
    "        zeroline=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        gridwidth=1,\n",
    "        zeroline=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002d5e43-0d29-46f0-aea3-18f3c34b1356",
   "metadata": {},
   "source": [
    "#### **Q3** What basic information can be summarized about the dataset (columns, data types, missing values)?\n",
    "A preliminary structural overview is necessary to assess data completeness and technical readiness for analysis, ensuring that variables like dates, authors, and subreddits are consistent and usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d8e95-6471-4ca1-b051-e9cd698763fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dac4701-0abb-4595-9d65-1ab7dba581f6",
   "metadata": {},
   "source": [
    "#### **Q4** Which specific conspiracy theories were most frequently discussed in 2020?\n",
    "Identifying the dominant themes reveals which narratives gained prominence during the pandemic and highlights shifts in the collective focus of conspiracy communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132af24-768b-4f4a-a257-cfe3a4d1c056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "groups = {\n",
    "    \"COVID-related\": [\"virus\", \"vaccine\", \"plandemic\"],\n",
    "    \"5G Technology\": [\"5g\"],\n",
    "    \"Global Elite\": [\"elite\", \"globalists\", \"bill gates\", \"epstein\", \"zuckerburg\"],\n",
    "    \"Deep State\": [\"deep state\", \"illuminati\", \"world order\", \"state\"],\n",
    "    \"Mind Control\": [\"mind control\"],\n",
    "    \"Fake News\": [\"fake news\", \"truth\"]\n",
    "}\n",
    "\n",
    "results = []\n",
    "for theme, words in groups.items():\n",
    "    total = 0\n",
    "    for w in words:\n",
    "        pattern = rf\"\\b{re.escape(w)}\\b\"\n",
    "        total += df[\"body\"].str.contains(pattern, case=False, na=False).sum()\n",
    "    results.append({\"Theme\": theme, \"Count\": total})\n",
    "\n",
    "themes_df = pd.DataFrame(results).sort_values(\"Count\", ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabfb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#0c2688\", \"#8d84bd\", \"#d3c1c1\", \"#ec9c9d\", \"#d43d51\", \"#26A57F\"]\n",
    "\n",
    "fig = px.bar(\n",
    "    themes_df,\n",
    "    x=\"Count\",\n",
    "    y=\"Theme\",\n",
    "    orientation=\"h\",\n",
    "    text=\"Count\",\n",
    "    color_discrete_sequence=[colors[0]],\n",
    "    title=\"Most Discussed Conspiracy Theory Groups (2020)\"\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition=\"outside\")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Number of Mentions\",\n",
    "    yaxis_title=\"Conspiracy Theme Group\",\n",
    "    showlegend=False,\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        gridwidth=1,\n",
    "        zeroline=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        gridwidth=1,\n",
    "        zeroline=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeca4b6-b460-4779-b2e7-f2805f00971e",
   "metadata": {},
   "source": [
    "### **Activity and Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1257424-bcf5-4907-b571-d966c9c73a00",
   "metadata": {},
   "source": [
    "#### **Q5** Which are the top 10 most active subreddits by number of posts/comments?\n",
    "Mapping activity levels across subreddits makes it possible to pinpoint where conspiracy discussions were most intense and which communities played a central role in shaping discourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5be58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_counts = df[\"subreddit\"].value_counts().head(10).reset_index()\n",
    "subreddit_counts.columns = [\"Subreddit\", \"Count\"]\n",
    "\n",
    "colors = [\"#0c2688\", \"#8d84bd\", \"#d3c1c1\", \"#ec9c9d\", \"#d43d51\", \"#26A57F\"]\n",
    "\n",
    "fig = px.bar(\n",
    "    subreddit_counts,\n",
    "    x=\"Count\",\n",
    "    y=\"Subreddit\",\n",
    "    orientation=\"h\",\n",
    "    text=\"Count\",\n",
    "    color_discrete_sequence=[colors[0]]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Top 10 Most Active Subreddits by Posts and Comments\",\n",
    "    xaxis_title=\"Number of Posts + Comments\",\n",
    "    yaxis_title=\"Subreddit\",\n",
    "    showlegend=False,\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        gridwidth=1,\n",
    "        zeroline=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        autorange=\"reversed\",\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        gridwidth=1,\n",
    "        zeroline=False\n",
    "    )\n",
    ")\n",
    "fig.update_traces(textposition=\"outside\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1fd6f-1f32-4d03-b09c-22f1b9a088c6",
   "metadata": {},
   "source": [
    "#### **Q6** Are there significant peaks of activity around major real-world events?\n",
    "Correlating posting spikes with external events sheds light on how online conspiracy discussions respond to triggers such as lockdown announcements, vaccine news, or political developments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15b2db7-076f-4eb5-b680-7ac17ab9de2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"created\"] = pd.to_datetime(df[\"created\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"created\"])\n",
    "\n",
    "df[\"month\"] = df[\"created\"].dt.to_period(\"M\")\n",
    "\n",
    "monthly_counts = (\n",
    "    df.groupby([\"month\", \"is_submission\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"Count\")\n",
    ")\n",
    "\n",
    "monthly_counts[\"month\"] = monthly_counts[\"month\"].astype(str)\n",
    "\n",
    "pivot = monthly_counts.pivot(index=\"month\", columns=\"is_submission\", values=\"Count\").fillna(0)\n",
    "pivot.columns = [\"Comments\", \"Submissions\"]\n",
    "pivot = pivot.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "colors = [\"#0c2688\", \"#8d84bd\", \"#d1bfbf\", \"#ec9c9d\", \"#d43d51\", \"#26A57F\"]\n",
    "\n",
    "df[\"created\"] = pd.to_datetime(df[\"created\"], errors=\"coerce\")\n",
    "df = df[(df[\"created\"] >= \"2020-01-01\") & (df[\"created\"] < \"2021-01-01\")]\n",
    "\n",
    "df[\"Submissions\"] = df[\"is_submission\"].astype(int)\n",
    "df[\"Comments\"] = (~df[\"is_submission\"]).astype(int)\n",
    "\n",
    "weekly = df.set_index(\"created\").resample(\"W\").agg(\n",
    "    Submissions=(\"Submissions\", \"sum\"),\n",
    "    Comments=(\"Comments\", \"sum\")\n",
    ").reset_index()\n",
    "\n",
    "weekly[\"Total\"] = weekly[\"Submissions\"] + weekly[\"Comments\"]\n",
    "weekly[\"Total\"] = weekly[\"Total\"].interpolate()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=weekly[\"created\"],\n",
    "    y=weekly[\"Total\"],\n",
    "    mode=\"lines\",\n",
    "    name=\"Total Activity\",\n",
    "    line=dict(color=colors[0], width=3)\n",
    "))\n",
    "\n",
    "events = {\n",
    "    \"2020-03-11\": \"WHO declares <br> pandemic\",\n",
    "    \"2020-04-01\": \"First <br> lockdowns\",\n",
    "    \"2020-12-15\": \"Vaccine <br> rollout begins\",\n",
    "    \"2020-05-25\": \"George Floyd’s <br> murder in Minneapolis\",\n",
    "    \"2020-07-15\": \"Massive Twitter hack\",\n",
    "    \"2020-07-02\": \"Ghislaine Maxwell<br>arrested<br>.\",\n",
    "    \"2020-11-03\": \"U.S. Presidential Election\"\n",
    "}\n",
    "\n",
    "for d, label in events.items():\n",
    "    ts = time.mktime(datetime.strptime(d, \"%Y-%m-%d\").timetuple()) * 1000\n",
    "    if d < \"2021-01-01\":\n",
    "        fig.add_vline(\n",
    "            x=ts,\n",
    "            line_width=1.5,\n",
    "            line_dash=\"dash\",\n",
    "            line_color=colors[4],\n",
    "            annotation_text=label,\n",
    "            annotation_position=\"top\",\n",
    "            annotation_font=dict(size=11, color=colors[4])\n",
    "        )\n",
    "fig.add_vrect(\n",
    "    x0=\"2020-03-23\", x1=\"2020-03-31\",\n",
    "    fillcolor=\"gray\",\n",
    "    opacity=0.15,\n",
    "    layer=\"below\",\n",
    "    line_width=0,\n",
    "    annotation_text=\"Data missing\",\n",
    "    annotation_position=\"top right\",\n",
    "    annotation_font=dict(size=11, color=\"gray\")\n",
    ")\n",
    "fig.add_vrect(\n",
    "    x0=\"2020-07-01\", x1=\"2020-08-01\",\n",
    "    fillcolor=\"blue\",\n",
    "    opacity=0.15,\n",
    "    layer=\"below\",\n",
    "    line_width=0\n",
    ")\n",
    "fig.add_annotation(\n",
    "    x=\"2020-07-15\",\n",
    "    y=0.03, yref=\"paper\",\n",
    "    text=\"Epstein–Maxwell case period\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=11, color=\"blue\"),\n",
    "    yanchor=\"bottom\"\n",
    ")\n",
    "\n",
    "fig.add_vrect(\n",
    "    x0=\"2020-10-15\", x1=\"2020-11-15\",\n",
    "    fillcolor=\"red\",\n",
    "    opacity=0.15,\n",
    "    layer=\"below\",\n",
    "    line_width=0\n",
    ")\n",
    "fig.add_annotation(\n",
    "    x=\"2020-10-30\",\n",
    "    y=0.03, yref=\"paper\",\n",
    "    text=\"U.S. Election period\",\n",
    "    showarrow=False,\n",
    "    font=dict(size=11, color=\"red\"),\n",
    "    yanchor=\"bottom\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Weekly Activity — Posts and Comments During 2020\",\n",
    "    xaxis_title=\"Month\",\n",
    "    yaxis_title=\"Number of Records\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    legend=dict(\n",
    "        title=None,\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\", y=1.02,\n",
    "        xanchor=\"right\", x=1\n",
    "    ),\n",
    "    xaxis=dict(\n",
    "        type=\"date\",\n",
    "        dtick=\"M1\",\n",
    "        tickformat=\"%b %Y\",\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        gridwidth=1,\n",
    "        zeroline=False,\n",
    "        range=[\"2020-01-01\", \"2020-12-31\"]\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        gridwidth=1,\n",
    "        zeroline=False\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f769c0-1efa-4d85-8116-bf0bd270e4a4",
   "metadata": {},
   "source": [
    "#### **Q7** How many unique authors are there, and how many contributions did each make? \n",
    "Examining author participation helps determine whether discourse was driven by a few prolific individuals or by a larger, more distributed group of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6831d1-9f6a-486e-b3ea-1974301b0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px \n",
    "\n",
    "\n",
    "counts = df[\"author\"].value_counts(dropna=False)\n",
    "author_counts = counts.rename_axis(\"Author\").reset_index(name=\"Contributions\")\n",
    "\n",
    "bins = author_counts[\"Contributions\"].value_counts().sort_index().reset_index()\n",
    "bins.columns = [\"Contributions\", \"Authors\"]\n",
    "bins[\"Contributions\"] = pd.to_numeric(bins[\"Contributions\"], errors=\"coerce\")\n",
    "bins[\"Authors\"] = pd.to_numeric(bins[\"Authors\"], errors=\"coerce\")\n",
    "\n",
    "ranges = [(11,20), (21,30), (31,40), (41,50), (51,100), (101, 1000)]\n",
    "group_rows = []\n",
    "for r in ranges:\n",
    "    low, high = r\n",
    "    group_rows.append({\n",
    "        \"Contributions\": f\"{low}-{high}\",\n",
    "        \"Authors\": bins.loc[\n",
    "            (bins[\"Contributions\"] >= low) & (bins[\"Contributions\"] <= high),\n",
    "            \"Authors\"\n",
    "        ].sum()\n",
    "    })\n",
    "\n",
    "over_1000 = bins.loc[bins[\"Contributions\"] > 1000, \"Authors\"].sum()\n",
    "group_rows.append({\"Contributions\": \">1000\", \"Authors\": over_1000})\n",
    "\n",
    "bins_trimmed = bins.loc[bins[\"Contributions\"] <= 10].copy()\n",
    "bins_final = pd.concat([bins_trimmed, pd.DataFrame(group_rows)], ignore_index=True)\n",
    "bins_final[\"Authors\"] = pd.to_numeric(bins_final[\"Authors\"], errors=\"coerce\")\n",
    "bins_final[\"Contributions\"] = bins_final[\"Contributions\"].astype(str)\n",
    "order = [str(i) for i in range(1, 11)] + [f\"{low}-{high}\" for (low, high) in ranges] + [\">1000\"]\n",
    "\n",
    "fig = px.bar(\n",
    "    bins_final,\n",
    "    x=\"Contributions\",\n",
    "    y=\"Authors\",\n",
    "    category_orders={\"Contributions\": order},\n",
    "    color_discrete_sequence=[\"#0c2688\"],\n",
    "    text=\"Authors\",\n",
    "    title=\"Number of Authors by Number of Contributions\"\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    texttemplate=\"%{text:,}\",\n",
    "    textposition=\"outside\",\n",
    "    marker_line_width=0.5,\n",
    "    marker_line_color=\"white\",\n",
    "    opacity=0.9\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Number of Contributions (posts + comments)\",\n",
    "    yaxis_title=\"Number of Authors\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    xaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1, zeroline=False),\n",
    "    yaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1, zeroline=False)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [\n",
    "    (\"1\", bins.loc[bins[\"Contributions\"] == 1, \"Authors\"].sum()),\n",
    "    (\"2–5\", bins.loc[(bins[\"Contributions\"] >= 2) & (bins[\"Contributions\"] <= 5), \"Authors\"].sum()),\n",
    "    (\"6–10\", bins.loc[(bins[\"Contributions\"] >= 6) & (bins[\"Contributions\"] <= 10), \"Authors\"].sum()),\n",
    "    (\"11–50\", bins.loc[(bins[\"Contributions\"] >= 11) & (bins[\"Contributions\"] <= 50), \"Authors\"].sum()),\n",
    "    (\"51+\", bins.loc[bins[\"Contributions\"] > 50, \"Authors\"].sum())\n",
    "]\n",
    "\n",
    "pie_data = pd.DataFrame(groups, columns=[\"Contribution Range\", \"Authors\"])\n",
    "\n",
    "colors = [\"#0c2688\", \"#8d84bd\", \"#ceaae6\", \"#ec9c9d\", \"#d43d51\"]\n",
    "\n",
    "fig = px.pie(\n",
    "    pie_data,\n",
    "    names=\"Contribution Range\",\n",
    "    values=\"Authors\",\n",
    "    color_discrete_sequence=colors,\n",
    "    title=\"Share of Authors by Contribution Range\"\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    textinfo=\"label+percent\",\n",
    "    insidetextorientation=\"radial\",\n",
    "    textfont_size=13\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_font_size=18,\n",
    "    plot_bgcolor=\"white\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2d7c3-8913-424c-9678-190c7fa50aef",
   "metadata": {},
   "source": [
    "#### **Q8** Which subreddits have the highest average score versus the highest post volume?\n",
    "This comparison exposes differences between popularity and engagement—some communities may generate large amounts of content, while others achieve greater approval or influence per post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e4ed6-6fe1-4448-b422-a7813eac1da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "subreddit_stats = (\n",
    "    df.groupby(\"subreddit\")\n",
    "    .agg(avg_score=(\"score\", \"mean\"), post_volume=(\"subreddit\", \"count\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "volume_cutoff = np.percentile(subreddit_stats[\"post_volume\"], 99)\n",
    "score_cutoff = np.percentile(subreddit_stats[\"avg_score\"], 99)\n",
    "filtered = subreddit_stats[\n",
    "    (subreddit_stats[\"post_volume\"] <= volume_cutoff) &\n",
    "    (subreddit_stats[\"avg_score\"] <= score_cutoff)\n",
    "]\n",
    "\n",
    "vmin, vmax = np.percentile(filtered[\"avg_score\"], [5, 95])\n",
    "\n",
    "fig = px.scatter(\n",
    "    filtered,\n",
    "    x=\"post_volume\",\n",
    "    y=\"avg_score\",\n",
    "    size=\"post_volume\",\n",
    "    color=\"avg_score\",\n",
    "    hover_name=\"subreddit\",\n",
    "    color_continuous_scale=[\n",
    "        \"#0c2688\", \"#3855b2\", \"#8d84bd\", \"#ec9c9d\", \"#d43d51\"\n",
    "    ],\n",
    "    range_color=[vmin, vmax],\n",
    "    title=\"Average Score vs Post Volume by Subreddit (Focused View)\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"log\",\n",
    "    title=\"Post Volume (log scale)\",\n",
    "    range=[np.log10(filtered[\"post_volume\"].min()), np.log10(volume_cutoff)]\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title=\"Average Score\",\n",
    "    range=[filtered[\"avg_score\"].min(), score_cutoff]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    coloraxis_colorbar=dict(\n",
    "        title=\"Avg Score\",\n",
    "        tickvals=np.linspace(vmin, vmax, 6).round(1)\n",
    "    ),\n",
    "    xaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1),\n",
    "    yaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23502664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "subreddit_stats = (\n",
    "    df.groupby(\"subreddit\")\n",
    "    .agg(avg_score=(\"score\", \"mean\"), post_volume=(\"subreddit\", \"count\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "volume_cutoff = np.percentile(subreddit_stats[\"post_volume\"], 99)\n",
    "score_cutoff = np.percentile(subreddit_stats[\"avg_score\"], 99)\n",
    "filtered = subreddit_stats[\n",
    "    (subreddit_stats[\"post_volume\"] <= volume_cutoff) &\n",
    "    (subreddit_stats[\"avg_score\"] <= score_cutoff)\n",
    "]\n",
    "\n",
    "vmin, vmax = np.percentile(filtered[\"avg_score\"], [5, 95])\n",
    "\n",
    "fig = px.scatter(\n",
    "    filtered,\n",
    "    x=\"post_volume\",\n",
    "    y=\"avg_score\",\n",
    "    size=\"post_volume\",\n",
    "    color=\"avg_score\",\n",
    "    hover_name=\"subreddit\",\n",
    "    color_continuous_scale=[\n",
    "        \"#0c2688\", \"#3855b2\", \"#8d84bd\", \"#ec9c9d\", \"#d43d51\"\n",
    "    ],\n",
    "    range_color=[vmin, vmax],\n",
    "    title=\"Average Score vs Post Volume by Subreddit (Focused View)\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(\n",
    "    type=\"log\",\n",
    "    title=\"Post Volume (log scale)\",\n",
    "    range=[np.log10(filtered[\"post_volume\"].min()), np.log10(volume_cutoff)]\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    title=\"Average Score\",\n",
    "    range=[filtered[\"avg_score\"].min(), score_cutoff]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    coloraxis_colorbar=dict(\n",
    "        title=\"Avg Score\",\n",
    "        tickvals=np.linspace(vmin, vmax, 6).round(1)\n",
    "    ),\n",
    "    xaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1),\n",
    "    yaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d57fafa-a184-4507-bac1-3a8b3c9844b6",
   "metadata": {},
   "source": [
    "#### **Q9** Do different subreddits experience synchronized activity peaks?\n",
    "Studying temporal synchronization between communities can indicate information diffusion and interconnection among different conspiracy networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107dc74d-1027-4285-b392-0c31b90bd7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"created\"] = pd.to_datetime(df[\"created\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"created\"])\n",
    "\n",
    "top_subs = df[\"subreddit\"].value_counts().head(6).index\n",
    "df_top = df[df[\"subreddit\"].isin(top_subs)].copy()\n",
    "\n",
    "df_top.loc[:, \"month\"] = df_top[\"created\"].apply(lambda x: x.strftime(\"%Y-%m\"))\n",
    "activity = df_top.groupby([\"month\", \"subreddit\"]).size().reset_index(name=\"ActivityCount\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#0c2688\", \"#8d84bd\", \"#26A57F\", \"#ec9c9d\", \"#d43d51\", \"#e3b23c\"]\n",
    "activity[\"month\"] = activity[\"month\"].astype(str)\n",
    "\n",
    "fig = px.line(\n",
    "    activity,\n",
    "    x=\"month\",\n",
    "    y=\"ActivityCount\",\n",
    "    color=\"subreddit\",\n",
    "    color_discrete_sequence=colors,\n",
    "    title=\"Activity Trends of Top Subreddits Over Time (Log Scale)\"\n",
    ")\n",
    "\n",
    "fig.update_traces(mode=\"lines+markers\", line=dict(width=2))\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Month (2020)\",\n",
    "    yaxis_title=\"Number of Posts / Comments (log scale)\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    legend_title_text=\"Subreddit\",\n",
    "    yaxis_type=\"log\",\n",
    "    xaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1),\n",
    "    yaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1)\n",
    ")\n",
    "\n",
    "events = {\n",
    "    \"2020-04-01\": \"First lockdowns\",\n",
    "    \"2020-07-02\": \"Ghislaine Maxwell arrested\",\n",
    "    \"2020-11-03\": \"US Presidential Election\"\n",
    "}\n",
    "\n",
    "for date, label in events.items():\n",
    "    date_dt = pd.to_datetime(date)\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=date_dt,\n",
    "        x1=date_dt,\n",
    "        y0=0,\n",
    "        y1=1,\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "        line=dict(color=\"#d43d51\", width=1.5, dash=\"dash\")\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        x=date_dt,\n",
    "        y=1,\n",
    "        yref=\"paper\",\n",
    "        text=label,\n",
    "        showarrow=False,\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"bottom\",\n",
    "        font=dict(size=11, color=\"#d43d51\")\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e28ee-7d72-4067-b406-34c09898e494",
   "metadata": {},
   "source": [
    "#### **Q10** Do the most active authors post in many subreddits or focus on one community?\n",
    "Analyzing user posting patterns helps identify whether certain participants act as cross-community links or remain confined to specific ideological spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cc497-83c3-481d-8216-687b55953d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "activity = (\n",
    "    df.groupby(\"author\")\n",
    "    .agg(total_posts=(\"body\", \"count\"), unique_subs=(\"subreddit\", \"nunique\"))\n",
    "    .reset_index()\n",
    ")\n",
    "activity = activity[activity[\"total_posts\"] > 0]\n",
    "\n",
    "activity[\"total_posts\"] = np.clip(activity[\"total_posts\"], 1, 5000)\n",
    "activity[\"unique_subs\"] = np.clip(activity[\"unique_subs\"], 1, 50)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "activity[\"unique_subs_jitter\"] = activity[\"unique_subs\"] + rng.normal(0, 0.05, len(activity))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f381c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "top_subs = df[\"subreddit\"].value_counts().head(10).index\n",
    "top_authors = df[\"author\"].value_counts().head(300).index\n",
    "filtered = df[df[\"subreddit\"].isin(top_subs) & df[\"author\"].isin(top_authors)]\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in filtered.iterrows():\n",
    "    G.add_node(row[\"author\"], type=\"author\")\n",
    "    G.add_node(row[\"subreddit\"], type=\"subreddit\")\n",
    "    G.add_edge(row[\"author\"], row[\"subreddit\"])\n",
    "\n",
    "authors_low, authors_mid, authors_high = [], [], []\n",
    "for n in G.nodes():\n",
    "    if G.nodes[n][\"type\"] == \"author\":\n",
    "        degree = len(list(G.neighbors(n)))\n",
    "        if degree > 5:\n",
    "            authors_high.append(n)\n",
    "        elif degree > 3:\n",
    "            authors_mid.append(n)\n",
    "        else:\n",
    "            authors_low.append(n)\n",
    "\n",
    "subreddits = [n for n, d in G.nodes(data=True) if d[\"type\"] == \"subreddit\"]\n",
    "\n",
    "pos = nx.shell_layout(G, nlist=[subreddits, authors_high, authors_mid, authors_low], scale=2)\n",
    "for n in subreddits:\n",
    "    pos[n] = pos[n] * 1.5  \n",
    "\n",
    "x_edges, y_edges = [], []\n",
    "for edge in G.edges():\n",
    "    x_edges += [pos[edge[0]][0], pos[edge[1]][0], None]\n",
    "    y_edges += [pos[edge[0]][1], pos[edge[1]][1], None]\n",
    "\n",
    "palette = [\"#12258f\", \"#9084c0\", \"#f1f1f1\", \"#f09fa2\", \"#de425b\"]\n",
    "colors = {\n",
    "    \"author_low\":  palette[0],\n",
    "    \"author_mid\":  palette[1],\n",
    "    \"author_high\": palette[3],\n",
    "    \"subreddit\":   palette[4],\n",
    "}\n",
    "\n",
    "node_colors, node_sizes = [], []\n",
    "author_categories = {\"≤3\": 0, \"4–5\": 0, \">5\": 0}\n",
    "\n",
    "for n in G.nodes():\n",
    "    degree = len(list(G.neighbors(n)))\n",
    "    if G.nodes[n][\"type\"] == \"subreddit\":\n",
    "        node_colors.append(colors[\"subreddit\"])\n",
    "        node_sizes.append(np.log1p(degree) * 14)\n",
    "    else:\n",
    "        if degree > 5:\n",
    "            node_colors.append(colors[\"author_high\"])\n",
    "            author_categories[\">5\"] += 1\n",
    "        elif degree > 3:\n",
    "            node_colors.append(colors[\"author_mid\"])\n",
    "            author_categories[\"4–5\"] += 1\n",
    "        else:\n",
    "            node_colors.append(colors[\"author_low\"])\n",
    "            author_categories[\"≤3\"] += 1\n",
    "        node_sizes.append(np.log1p(degree) * 9)\n",
    "\n",
    "total_authors = sum(author_categories.values())\n",
    "author_percentages = {\n",
    "    group: round((count / total_authors) * 100, 1)\n",
    "    for group, count in author_categories.items()\n",
    "}\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=x_edges, y=y_edges,\n",
    "    mode=\"lines\",\n",
    "    line=dict(width=0.7, color=\"rgba(0,0,0,0.25)\"),\n",
    "    hoverinfo=\"none\",\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[pos[n][0] for n in G.nodes()],\n",
    "    y=[pos[n][1] for n in G.nodes()],\n",
    "    mode=\"markers\",\n",
    "    marker=dict(\n",
    "        size=node_sizes,\n",
    "        color=node_colors,\n",
    "        opacity=0.9,\n",
    "        line=dict(width=0.8, color=\"white\")\n",
    "    ),\n",
    "    hovertext=[\n",
    "        f\"<b>{n}</b><br>Type: {G.nodes[n]['type']}<br>Connections: {len(list(G.neighbors(n)))}\"\n",
    "        for n in G.nodes()\n",
    "    ],\n",
    "    hoverinfo=\"text\",\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[pos[n][0] for n in subreddits],\n",
    "    y=[pos[n][1] for n in subreddits],\n",
    "    mode=\"text\",\n",
    "    text=subreddits,\n",
    "    textposition=\"top center\",\n",
    "    textfont=dict(size=14, color=\"rgba(0,0,0,0.85)\"),\n",
    "    hoverinfo=\"none\",\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',\n",
    "    marker=dict(size=10, color=colors[\"author_low\"]),\n",
    "    name=f'Author ≤3 subs ({author_percentages[\"≤3\"]}%)'))\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',\n",
    "    marker=dict(size=10, color=colors[\"author_mid\"]),\n",
    "    name=f'Author 4–5 subs ({author_percentages[\"4–5\"]}%)'))\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',\n",
    "    marker=dict(size=10, color=colors[\"author_high\"]),\n",
    "    name=f'Author >5 subs ({author_percentages[\">5\"]}%)'))\n",
    "fig.add_trace(go.Scatter(x=[None], y=[None], mode='markers',\n",
    "    marker=dict(size=10, color=colors[\"subreddit\"]),\n",
    "    name=\"Subreddit\"))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Network of Authors and Subreddits — Cross-Posting Patterns\",\n",
    "    title_font_size=18,\n",
    "    plot_bgcolor=\"white\",\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\", y=-0.15,\n",
    "        xanchor=\"center\", x=0.5,\n",
    "        font=dict(size=12)\n",
    "    ),\n",
    "    xaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
    "    yaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
    "    margin=dict(l=40, r=40, t=70, b=50)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147c682-e486-4530-8d85-8e9c49e12e74",
   "metadata": {},
   "source": [
    "#### **Q11** How does the average score (karma/upvotes) change over time?\n",
    "Tracking how post scores evolve provides insight into shifting community attitudes and levels of endorsement toward conspiracy-related content throughout the pandemic year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994cc444-b6da-4563-8ed5-2d999c41cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"created\"] = pd.to_datetime(df[\"created\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"created\", \"score\"])\n",
    "\n",
    "df[\"month\"] = df[\"created\"].dt.to_period(\"M\").dt.to_timestamp()\n",
    "\n",
    "avg_scores = (\n",
    "    df.groupby(\"month\")[\"score\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .sort_values(\"month\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccebd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#0c2688\", \"#8d84bd\", \"#d43d51\", \"#26A57F\", \"#ec9c9d\", \"#e3b23c\"]\n",
    "\n",
    "\n",
    "fig = px.area(\n",
    "    avg_scores,\n",
    "    x=\"month\",\n",
    "    y=\"score\",\n",
    "    color_discrete_sequence=[colors[0]],\n",
    "    title=\"Average Post/Comment Score Over Time (Density Plot)\",\n",
    "    labels={\n",
    "        \"month\": \"Month (2020)\",\n",
    "        \"score\": \"Average Score (Karma/Upvotes)\"\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    line=dict(width=3, color=colors[0]),\n",
    "    fill='tozeroy',\n",
    "    opacity=0.5\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    xaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        zeroline=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        showgrid=True,\n",
    "        gridcolor=\"rgba(0,0,0,0.1)\",\n",
    "        zeroline=False\n",
    "    ),\n",
    "    font=dict(family=\"Open Sans\", size=13, color=\"#333\"),\n",
    "    margin=dict(l=60, r=40, t=80, b=60)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dfcaa6-c1a0-43dc-858e-b1e96476d3a8",
   "metadata": {},
   "source": [
    "### **Content Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b94e444-69ed-4a34-8c7d-1c7ce41ff56a",
   "metadata": {},
   "source": [
    "#### **Q12** What is the overall sentiment distribution of all comments and submissions?\n",
    "Sentiment analysis reveals the emotional atmosphere of conspiracy discussions, indicating whether fear, anger, or hope dominated online exchanges in 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69767ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent = pd.read_csv(\"sentiment.csv\")\n",
    "\n",
    "emotion_cols = [col for col in df_sent.columns if col in [\n",
    "    \"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\",\n",
    "    \"sadness\", \"surprise\", \"trust\"\n",
    "]]\n",
    "\n",
    "emotion_summary = df_sent[emotion_cols].sum().sort_values(ascending=False).reset_index()\n",
    "emotion_summary.columns = [\"Emotion\", \"Count\"]\n",
    "emotion_summary[\"Percent\"] = emotion_summary[\"Count\"] / emotion_summary[\"Count\"].sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a288448",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#9b5bbb\", \"#36553C\", \"#d4b544\", \"#bcd377\", \"#4436ad\", \"#5DB2B1\", \"#8e2424\", \"#127950\"]\n",
    "\n",
    "fig = px.bar(\n",
    "    emotion_summary,\n",
    "    x=\"Emotion\",\n",
    "    y=\"Percent\",\n",
    "    color=\"Emotion\",\n",
    "    color_discrete_sequence=colors,\n",
    "    title=\"Overall Emotion Distribution in Reddit Dataset\"\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Emotion\",\n",
    "    yaxis_title=\"Percentage of Emotion Words\",\n",
    "    plot_bgcolor=\"white\",\n",
    "    title_font_size=18,\n",
    "    showlegend=False,\n",
    "    xaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1),\n",
    "    yaxis=dict(showgrid=True, gridcolor=\"rgba(0,0,0,0.1)\", gridwidth=1)\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9959f-3960-458c-8a02-fa3dbe34cee9",
   "metadata": {},
   "source": [
    "The overall sentiment distribution of Reddit discussions about conspiracy narratives in 2020 shows a strong emotional polarization. \n",
    "\n",
    "Negative sentiment dominates the conversations, slightly surpassing positive sentiment, while neutral posts form a much smaller portion. This indicates that conspiracy-related discussions were highly emotionally charged, with fear, distrust, and anger being particularly widespread. \n",
    "\n",
    "The sizable share of positive sentiment suggests the presence of hopeful or supportive narratives within these communities as well, but the prevalence of negativity reflects heightened anxiety and conflict during this period of global uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b614c26-54d6-4cc0-a311-8e0c3c43a87d",
   "metadata": {},
   "source": [
    "#### **Q13** What are the most positive and most negative subreddits overall?\n",
    "Comparing sentiment across communities makes it possible to identify where discourse tended to be more constructive, aggressive, or despairing, illustrating emotional diversity within the conspiracy sphere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d31e6-8b40-4339-be37-6afaf7c42b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c82a54a-012b-4ec7-a2be-d8600982bffb",
   "metadata": {},
   "source": [
    "#### **Q14** Are longer comments more emotionally expressive (stronger positive/negative values)? \n",
    "Exploring the relationship between comment length and emotional intensity can show whether detailed engagement corresponds to stronger affective expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6473e-11bb-47c3-8744-d673619d1635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db462e36-b603-4b90-b83e-d465f0bb5e1a",
   "metadata": {},
   "source": [
    "#### **Q15** How does sentiment vary between submissions and comments? \n",
    "Contrasting the tone of original posts with that of replies helps determine whether discussions amplify, neutralize, or challenge the initial emotional framing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f7904b-8697-4faa-ba25-b96bd4165b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cb28f2b-20b5-4b5c-9245-96be108dc29a",
   "metadata": {},
   "source": [
    "#### **Q16** Do posts with more positive sentiment tend to get higher scores? \n",
    "Assessing this relationship clarifies which emotional tones receive greater validation from the community, shedding light on collective preferences for positivity or outrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e378c3-5053-4369-b820-05a0908fbba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d84b798c-991d-4f39-b070-a66bfe7fb6f7",
   "metadata": {},
   "source": [
    "### **Interesring Findings** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b683c-5814-4f63-8178-610ebfadd899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18ffb387-45f4-4f4d-b09b-0977bad3321c",
   "metadata": {},
   "source": [
    "#### **Q17** Can recurring narratives or metaphors be identified? \n",
    "Recognizing repeated metaphors and storylines allows us to understand how conspiracy narratives are constructed symbolically, often relying on themes of awakening, deception, or hidden power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d9f70-008c-4acb-81a4-2ccdad8c1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-louvain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2489fb8-2e48-42ff-a6b0-452a442318b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import community.community_louvain as community_louvain\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "\n",
    "# load only the needed columns, faster\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Desktop\\uni\\CSS\\project\\dataset.csv\", usecols=[\"body\"])\n",
    "\n",
    "# custom conspiracy vocabulary\n",
    "conspiracy_terms = [\n",
    "    \"deep state\",\"truth\",\"wake up\",\"they control\",\"hidden\",\"elite\",\n",
    "    \"illuminati\",\"nwo\",\"new world order\",\"great awakening\",\n",
    "    \"plandemic\",\"sheeple\",\"mind control\",\"5g\",\"fake news\",\n",
    "    \"qanon\",\"cabal\",\"puppet\",\"big pharma\",\"globalists\",\n",
    "]\n",
    "\n",
    "# keep only rows containing conspiratorial themes\n",
    "pattern = r\"|\".join([re.escape(x) for x in conspiracy_terms])\n",
    "df = df[df[\"body\"].str.contains(pattern, case=False, na=False)]\n",
    "\n",
    "# cleaning function\n",
    "def clean(t):\n",
    "    t = str(t).lower()\n",
    "    t = re.sub(r\"http\\S+|www\\S+\", \" \", t)\n",
    "    t = re.sub(r\"[^a-z\\s]\", \" \", t)\n",
    "    words = [w for w in t.split() if w not in stop and len(w) > 2]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df[\"clean\"] = df[\"body\"].apply(clean)\n",
    "\n",
    "# bigram extractor\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2), min_df=15)\n",
    "X = vectorizer.fit_transform(df[\"clean\"])\n",
    "\n",
    "counts = X.sum(axis=0).A1\n",
    "bigrams = vectorizer.get_feature_names_out()\n",
    "bigram_freq = dict(zip(bigrams, counts))\n",
    "\n",
    "# sort by conspiracy relevance (keep only phrases that contain keywords)\n",
    "filtered_bigrams = {\n",
    "    bg:freq for bg,freq in bigram_freq.items()\n",
    "    if any(key in bg for key in [\"state\",\"truth\",\"wake\",\"control\",\"elite\",\"order\",\"5g\",\"qanon\",\"virus\",\"plandemic\"])\n",
    "}\n",
    "\n",
    "top_bigrams = Counter(filtered_bigrams).most_common(25)\n",
    "\n",
    "print(\"Top conspiracy bigrams:\\n\")\n",
    "for phrase, freq in top_bigrams:\n",
    "    print(f\"{phrase:35s} {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4411f19-2ced-480c-895c-935fd1ed0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import networkx as nx\n",
    "\n",
    "# --- build conspiracy graph from bigrams ---\n",
    "G = nx.Graph()\n",
    "\n",
    "for phrase, freq in top_bigrams:\n",
    "    w1, w2 = phrase.split()\n",
    "    G.add_edge(w1, w2, weight=freq)\n",
    "\n",
    "# --- Layout ---\n",
    "pos = nx.spring_layout(G, k=20, iterations=200, seed=42)\n",
    "\n",
    "# --- Edges ---\n",
    "edge_x, edge_y = [], []\n",
    "for edge in G.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x += [x0, x1, None]\n",
    "    edge_y += [y0, y1, None]\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=1.5, color='rgba(160,160,160,0.4)'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines'\n",
    ")\n",
    "\n",
    "# --- Nodes ---\n",
    "node_x, node_y = [], []\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "\n",
    "node_adjacencies = []\n",
    "node_text = []\n",
    "\n",
    "for node, adjacencies in G.adjacency():\n",
    "    deg = len(adjacencies)\n",
    "    node_adjacencies.append(deg)\n",
    "    node_text.append(f\"{node}<br>Connections: {deg}\")\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers+text',\n",
    "    hoverinfo='text',\n",
    "    text=[n for n in G.nodes()],\n",
    "    textposition=\"top center\",\n",
    "    textfont=dict(size=11, color=\"black\"),\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='Bluered',\n",
    "        color=node_adjacencies,\n",
    "        size=[12 + d * 3 for d in node_adjacencies],\n",
    "        line=dict(width=1, color='white'),\n",
    "        colorbar=dict(\n",
    "            thickness=12,\n",
    "            title='Connections',\n",
    "            xanchor='left'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Final figure ---\n",
    "fig = go.Figure(\n",
    "    data=[edge_trace, node_trace],\n",
    "    layout=go.Layout(\n",
    "        title=\"<b>Conspiracy Narratives — Network of Recurring Bigrams (Reddit 2020)</b>\",\n",
    "        titlefont_size=20,\n",
    "        showlegend=False,\n",
    "        hovermode='closest',\n",
    "        margin=dict(b=20, l=20, r=20, t=60),\n",
    "        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "        plot_bgcolor=\"white\"\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition=\"top center\")  \n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805d76f-244e-4c9e-8901-95d0a14c6e9d",
   "metadata": {},
   "source": [
    "Based on the 2020 Reddit data, the network graph shows that the concept of “truth” serves as the most central and highly connected hub within these conspiracy narratives.\n",
    "\n",
    "It functions as a core anchor that links directly to ideas related to seeking, knowing, and revealing — such as “find,” “know,” “tell,” “see,” and “want.”\n",
    "\n",
    "The visualization also highlights several distinct thematic clusters, including:\n",
    "- Global Control: “great elite,” “mind control,” “global virus,” “deep state”\n",
    "- New World Order: “order submission,” “world”\n",
    "- Call to Action: “wake,” “united,” “people,” “speak”\n",
    "\n",
    "Despite their differences, all these clusters are tied back to the central pursuit of truth, suggesting that it acts as the unifying concept across a wide range of conspiracy themes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79539cf4-62e7-4ef1-8a21-043a3625f3e2",
   "metadata": {},
   "source": [
    "#### **Q18** Which grammatical constructions are most common (imperative, interrogative, emotional)? \n",
    "Analyzing sentence structure helps reveal rhetorical strategies—whether users try to command, question, or emotionally appeal to others—to foster belief or participation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e2bad-1213-4619-a622-aa3393310d9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8b1c88f-eb92-47b4-aa41-bfd21d1db79e",
   "metadata": {},
   "source": [
    "#### **Q19** Has skepticism toward official statistics and mainstream media increased during the pandemic?\n",
    "Measuring changes in expressions of distrust provides evidence for whether COVID-19 intensified anti-establishment attitudes within conspiracy communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52c7792-5041-468d-8793-918fef69f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- Load dataset ---\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Desktop\\uni\\CSS\\project\\dataset.csv\", low_memory=False)\n",
    "\n",
    "# --- Keywords related to skepticism ---\n",
    "keywords = [\"fake news\", \"lies\", \"propaganda\", \"mainstream media\"]\n",
    "pattern = re.compile(r'\\b(?:' + '|'.join([re.escape(k) for k in keywords]) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "# --- Ensure 'created' column exists and convert to datetime ---\n",
    "if 'created' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['created'], errors='coerce')\n",
    "elif 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "else:\n",
    "    raise KeyError(\"DataFrame must have a date column ('created' or 'date').\")\n",
    "\n",
    "# --- Create 'month' column ---\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "\n",
    "# --- Create separate columns for each keyword ---\n",
    "for kw in keywords:\n",
    "    df[kw] = df['body'].astype(str).str.count(re.escape(kw), flags=re.IGNORECASE)\n",
    "\n",
    "# --- Sum per month for each keyword ---\n",
    "monthly_keywords = df.groupby('month')[keywords].sum().reset_index()\n",
    "monthly_keywords['month'] = monthly_keywords['month'].dt.to_timestamp()\n",
    "\n",
    "# --- Ensure numeric data ---\n",
    "for kw in keywords:\n",
    "    monthly_keywords[kw] = pd.to_numeric(monthly_keywords[kw], errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6a20d2-e5ba-44e5-9ecf-b4687919970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define color palette ---\n",
    "colors = [\"#eff3ff\", \"#bdd7e7\", \"#6baed6\", \"#2171b5\"]\n",
    "\n",
    "# --- Create filled area chart with Plotly ---\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, kw in enumerate(keywords):\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=monthly_keywords['month'],\n",
    "        y=monthly_keywords[kw],\n",
    "        name=kw,\n",
    "        mode='lines',\n",
    "        line=dict(width=0.5, color=colors[i]),\n",
    "        stackgroup='one',  # enables stacked area\n",
    "        groupnorm='',\n",
    "        fillcolor=colors[i]\n",
    "    ))\n",
    "\n",
    "# --- Customize layout ---\n",
    "fig.update_layout(\n",
    "    title='Skepticism toward Official Statistics and Mainstream Media in 2020',\n",
    "    xaxis_title='Month',\n",
    "    yaxis_title='Number of Mentions',\n",
    "    template='plotly_white',\n",
    "    legend_title_text='Keywords',\n",
    "    font=dict(size=13),\n",
    "    xaxis=dict(showgrid=False),\n",
    "    yaxis=dict(showgrid=True, zeroline=False)\n",
    ")\n",
    "\n",
    "# --- Show interactive chart ---\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35f2979-8aad-4318-981a-c73167f9b652",
   "metadata": {},
   "source": [
    "The data indicate that skepticism toward official statistics and mainstream media experienced noticeable fluctuations throughout 2020, closely corresponding with key phases of the COVID-19 pandemic. In the early months of the year, public discussion around misinformation and distrust remained relatively stable. However, beginning in March 2020—when the pandemic was officially declared—there was a clear increase in the number of mentions of terms such as “fake news,” “propaganda,” “lies,” and “mainstream media.” This suggests that the health crisis and the accompanying information overload amplified public doubts about the credibility of institutional communication and media reporting.\n",
    "\n",
    "While this surge slightly declined in mid-2020, skepticism remained consistently higher than pre-pandemic levels, with another peak visible toward the end of the year. This secondary rise likely reflects renewed tensions around political polarization, vaccine announcements, and continued debates over misinformation.\n",
    "\n",
    "Overall, the evidence supports the conclusion that the COVID-19 pandemic acted as a catalyst for growing distrust in traditional information sources. The sustained visibility of skeptical discourse throughout 2020 illustrates how global crises can intensify public questioning of authority, expertise, and the reliability of official narratives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1363aa9-b7e7-47dd-a70e-2f152519a758",
   "metadata": {},
   "source": [
    "#### **Q20** Does the language of users who discuss COVID differ from that of those discussing other conspiracy topics?\n",
    "Comparing linguistic patterns highlights how the pandemic introduced new vocabularies—medical, scientific, or apocalyptic—and reshaped discourse styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a63c39-4905-405a-8790-06aeefe77710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# --- 0. Очищення даних ---\n",
    "# заміна NaN і чисел на рядки, щоб уникнути TypeError\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Desktop\\uni\\CSS\\project\\dataset.csv\", low_memory=False)\n",
    "df['body'] = df['body'].fillna('').astype(str)\n",
    "\n",
    "# --- 1. Identify COVID-related posts ---\n",
    "covid_keywords = [\"covid\", \"coronavirus\", \"pandemic\", \"vaccine\", \"vaccines\", \"lockdown\", \"virus\", \"pfizer\"]\n",
    "pattern = r'\\b(' + '|'.join(covid_keywords) + r')\\b'\n",
    "\n",
    "df['category'] = df['body'].str.lower().apply(\n",
    "    lambda x: 'covid' if re.search(pattern, x) else 'non-covid'\n",
    ")\n",
    "\n",
    "# --- 2. Text cleaning ---\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['clean'] = df['body'].apply(clean_text)\n",
    "\n",
    "#--- 3. Split into two groups ---\n",
    "covid_texts = df[df['category'] == 'covid']['clean']\n",
    "other_texts = df[df['category'] == 'non-covid']['clean']\n",
    "\n",
    "# --- 4. Count word frequencies ---\n",
    "vectorizer = CountVectorizer(max_features=20, stop_words='english')\n",
    "covid_counts = np.sum(vectorizer.fit_transform(covid_texts).toarray(), axis=0)\n",
    "covid_vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=covid_vocab, stop_words='english')\n",
    "other_counts = np.sum(vectorizer.fit_transform(other_texts).toarray(), axis=0)\n",
    "\n",
    "# --- 5. Prepare DataFrame for heatmap ---\n",
    "heatmap_df = pd.DataFrame({\n",
    "    'COVID': covid_counts,\n",
    "    'Non-COVID': other_counts\n",
    "}, index=covid_vocab)\n",
    "\n",
    "# нормалізуємо для порівняння\n",
    "#heatmap_df = heatmap_df.div(heatmap_df.sum(axis=0), axis=1)\n",
    "# --- нормалізація до відносних частот ---\n",
    "heatmap_df = heatmap_df.div(heatmap_df.sum(axis=0), axis=1) * 100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861331c-ba62-4e0f-8d92-dd4005ddc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- Build interactive heatmap with Plotly ---\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=heatmap_df.values,                # matrix of values\n",
    "    x=heatmap_df.columns,               # category labels\n",
    "    y=heatmap_df.index,                 # word labels\n",
    "    colorscale='YlGnBu',                # same color palette as Seaborn\n",
    "    text=heatmap_df.round(1),           # annotations with 1 decimal\n",
    "    texttemplate=\"%{text}\",             # show annotations\n",
    "    colorbar=dict(title='Frequency (%)')  # colorbar title\n",
    "))\n",
    "\n",
    "# --- Layout customization ---\n",
    "fig.update_layout(\n",
    "    title=\"Word Frequency Comparison: COVID vs Non-COVID Conspiracies\",\n",
    "    xaxis_title=\"Category\",\n",
    "    yaxis_title=\"Words\",\n",
    "    template='plotly_white',\n",
    "    font=dict(size=12),\n",
    "    width=900,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "# --- Show interactive chart ---\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa23c88-277e-4b16-9d03-fa51cf762c57",
   "metadata": {},
   "source": [
    "The comparison of word frequencies between COVID-related and non-COVID conspiracy discussions reveals distinct linguistic patterns that reflect the specific focus and context of each topic. In COVID-related conspiracies, users more frequently use terms such as “virus,” “vaccine,” “vaccines,” and “covid,” which directly reference the health crisis and associated medical themes. This indicates a discourse centered on public health, disease transmission, and skepticism toward scientific or governmental handling of the pandemic.\n",
    "\n",
    "Conversely, non-COVID conspiracy discussions are dominated by more general or socially oriented language, with higher frequencies for words such as “people,” “like,” “just,” and “think.” These words suggest broader discussions about human behavior, belief systems, and opinion-sharing rather than specific scientific or epidemiological issues.\n",
    "\n",
    "Overall, the linguistic divergence suggests that while COVID-related conspiracies are grounded in biomedical and institutional skepticism, non-COVID conspiracies tend to emphasize social dynamics, perception, and general distrust. This difference highlights how global crises like the pandemic reshape not only the content but also the linguistic framing of conspiratorial discourse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653af51b-5ed5-447d-a3b5-a83f1134dd54",
   "metadata": {},
   "source": [
    "#### **Q21** Did global events of 2020 (the pandemic, protests, elections, and vaccination) influence the rise or decline of religious rhetoric in conspiracy theories?\n",
    "This research helps us understand how global crises and social upheavals shape the language and themes of conspiracy narratives. By analyzing the fluctuations in religious references, we can see how faith-based explanations emerge as coping mechanisms during uncertainty and how religion becomes intertwined with misinformation or ideological polarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87f81f-6ec5-4cd6-9d63-fddf8f6a2273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- Завантаження ---\n",
    "df = pd.read_csv(r\"C:\\Users\\User\\Desktop\\uni\\CSS\\project\\dataset.csv\", low_memory=False)\n",
    "\n",
    "# --- Ключові слова ---\n",
    "religious_keywords = [\n",
    "    \"god\", \"jesus\", \"christ\", \"bible\", \"faith\", \"church\", \"pray\", \n",
    "    \"religion\", \"satan\", \"prophecy\", \"heaven\", \"hell\", \"angel\", \"devil\"\n",
    "]\n",
    "\n",
    "# --- Попередня обробка ---\n",
    "df[\"body\"] = df[\"body\"].astype(str).str.lower()\n",
    "df[\"created\"] = pd.to_datetime(df[\"created\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"created\"])\n",
    "df = df[df[\"created\"].dt.year == 2020]\n",
    "\n",
    "# --- Ознака релігійних текстів ---\n",
    "pattern = \"|\".join(religious_keywords)\n",
    "df[\"is_religious\"] = df[\"body\"].str.contains(pattern, case=False, regex=True)\n",
    "\n",
    "# --- Агрегація по тижнях ---\n",
    "df[\"week\"] = df[\"created\"].dt.to_period(\"W\").apply(lambda r: r.start_time)\n",
    "weekly = df.groupby(\"week\")[\"is_religious\"].mean().reset_index()\n",
    "weekly.columns = [\"week\", \"religious_ratio\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b6f722-c393-4856-985c-359339428f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Основні події ---\n",
    "events = {\n",
    "    \"2020-02-17\": \"Christian feast day\",\n",
    "    \"2020-03-11\": \"COVID-19 pandemic\",\n",
    "    \"2020-04-13\": \"Easter Monday\",\n",
    "    \"2020-05-25\": \"George Floyd protests\",\n",
    "    \"2020-07-06\": \"Birthday of the 14th Dalai Lama\",\n",
    "    \"2020-08-04\": \"Beirut explosion\",\n",
    "    \"2020-09-28\": \"Yom Kippur\",\n",
    "    \"2020-11-03\": \"US presidential election\",\n",
    "    \"2020-12-14\": \"First COVID-19 vaccines\",\n",
    "}\n",
    "\n",
    "# --- 🔹 Інтерактивний графік ---\n",
    "fig = go.Figure()\n",
    "\n",
    "# --- Лінія часу релігійних згадок ---\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=weekly[\"week\"],\n",
    "    y=weekly[\"religious_ratio\"],\n",
    "    mode=\"lines+markers\",\n",
    "    name=\"Religious mentions\",\n",
    "    line=dict(color=\"#0d47a1\", width=3),\n",
    "    marker=dict(size=6, color=\"#1976d2\", line=dict(width=1, color=\"#0a2a6b\")),\n",
    "    hovertemplate=\"<b>%{x|%b %d, %Y}</b><br>Share: %{y:.3f}<extra></extra>\"\n",
    "))\n",
    "\n",
    "# --- Вертикальні лінії + анотації (чергування верх/низ) ---\n",
    "for i, (date_str, label) in enumerate(events.items()):\n",
    "    date = pd.to_datetime(date_str).to_pydatetime()\n",
    "    \n",
    "    # Лінія події\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=date, x1=date,\n",
    "        y0=0, y1=1,\n",
    "        xref=\"x\", yref=\"paper\",\n",
    "        line=dict(color=\"rgba(0,0,80,0.25)\", width=2, dash=\"dot\")\n",
    "    )\n",
    "\n",
    "    # Чергування позицій  \n",
    "    bottom_labels = {\"2020-05-25\", \"2020-11-03\", \"2020-07-06\", \"2020-12-14\"} \n",
    "    \n",
    "    if date_str in bottom_labels:\n",
    "        y_pos = -0.05\n",
    "        angle = 25\n",
    "    else:\n",
    "        y_pos = 1.02\n",
    "        angle = 25\n",
    "\n",
    "    # Додавання підпису\n",
    "    fig.add_annotation(\n",
    "        x=date,\n",
    "        y=y_pos,\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "        showarrow=False,\n",
    "        text=label,\n",
    "        font=dict(size=10, color=\"black\"),\n",
    "        textangle=angle\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Оформлення ---\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        \"text\": \"Religious References in Conspiracy Discussions (2020)<br><sup>with Key Global Events</sup>\",\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"font\": dict(size=18)\n",
    "    },\n",
    "    xaxis_title=\"Week of 2020\",\n",
    "    yaxis_title=\"Share of religious texts\",\n",
    "    template=\"plotly_white\",\n",
    "    hovermode=\"x unified\",\n",
    "    plot_bgcolor=\"#f9fbff\",\n",
    "    paper_bgcolor=\"#f9fbff\",\n",
    "    font=dict(color=\"#0a2a6b\"),\n",
    ")\n",
    "\n",
    "# --- Вісь X обмежити 2020 ---\n",
    "fig.update_xaxes(range=[\"2020-01-01\", \"2020-12-31\"])\n",
    "\n",
    "# --- Збереження ---\n",
    "fig.write_html(\"religious_trends_2020.html\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d88a76-08d5-48a3-b153-ad9f605d5bc0",
   "metadata": {},
   "source": [
    "The data presented in the graph demonstrate that the presence of religious themes within conspiracy theory discussions fluctuated in close relation to major global events throughout 2020. Notably, during periods of intense socio-political and public health crises—such as the official declaration of the COVID-19 pandemic or the U.S. presidential election—the share of religious references declined significantly. This suggests that, in moments of acute global tension, conspiracy narratives tended to focus more on political, scientific, or institutional explanations rather than invoking religious frameworks.\n",
    "\n",
    "In contrast, during religious holidays and spiritually symbolic dates—such as Easter Monday or the birthday of the 14th Dalai Lama—there was a clear rise in the frequency of religious rhetoric. These peaks imply that collective religious observances may serve as catalysts for renewed interest in theological or eschatological interpretations within conspiratorial discourse.\n",
    "\n",
    "Overall, the findings indicate that religious references in conspiracy discussions are not constant but context-dependent: they tend to diminish during periods dominated by secular crises and resurface during times of religious or spiritual significance. This pattern highlights the dynamic interaction between religion, collective emotion, and the search for meaning in the face of uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2368fa56-2cea-4f3e-b33e-1e0d5bba2398",
   "metadata": {},
   "source": [
    "#### **Q22** Which keywords most strongly co-occur with “COVID” or “virus”?\n",
    "Identifying keyword co-occurrences uncovers how different ideas—such as “5G,” “vaccine,” “control,” or “Bill Gates”—clustered around the concept of the virus, revealing the structure of pandemic-related conspiracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c57979-d282-4d4a-a7fb-c538612896f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc39bb-6d46-4248-b110-11cb80ab11c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
